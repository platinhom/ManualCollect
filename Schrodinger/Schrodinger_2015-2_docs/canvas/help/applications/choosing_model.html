<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta http-equiv="Content-Style-Type" content="text/css">
<meta name="categories" content="{categories}">
<meta name="product" content="{product}">
<link rel="stylesheet" href="../support/help.css" charset="ISO-8859-1" type="text/css">
<title>Choosing a Model</title>
</head>
<script type="text/javascript">
function setTitle()
{
top.document.title = document.title + " - " + parent.parent.WINDOW_TITLE;
}
</script>
<body onload="setTitle();">
<table bgcolor="#dcdcdc" border="0" cellspacing="0" width="100%">
<tr><td>
<p><img src="../images/common/schrodinger_logo.png" align="left" alt=""
 border="0" hspace="5" vspace="5" /></p>
</td></tr>
<tr><td>
<h1 class="title"><span class="schrored">Choosing a Model</span></h1>
</td></tr>
</table>

<p>Canvas provides a range of models for predicting values of properties.
Some advice on how to choose the best model for the application that you are
interested in is given below.
</p>

<p><b>By method:</b></p>

<ul>
<li><p><b>Partial Least Squares (PLS)</b> and <b>Kernel-Based Partial Least
Squares (KPLS)</b>&mdash;These are good methods for large numbers of X
variables, with both underdetermined and overdetermined systems. PLS is not
available with fingerprints as X variables (due to legal reasons), but KPLS is.
PLS and KPLS give comparable performance. The (K)PLS &quot;factors&quot; are
constructed as linear combinations of the X variables, by correlating the X
variables with Y.
</p></li>
<li><p><b>Principal Component Analysis Regression (PCA)</b>&mdash;A good method
for large numbers of X variables. The principal components are constructed
as linear combinations of X variables to maximize the variance in X. The results
for the training set are not as good as PLS and KPLS, but may be useful when
these methods give poor test set predictions.
</p></li>
<li><p><b>Multiple Linear Regression (MLR)</b>&mdash;Use this method if you have
a relatively small number of X variables, especially in conjunction with
determination of the best subsets. For larger numbers of X variables (e.g. 50),
PLS and KPLS are preferred because they are able to handle high collinearities
in the X variables.
</p></li>
<li><p><b>Recursive Partitioning (RP)</b> and <b>Bayes
Classification</b>&mdash;Use these methods for categorical data. It can be
useful to partition a continuous Y variable and try one of these methods if the
PLS, PCA, or MLR methods do not give good results. Recursive Partitioning (RP)
performs better than Bayes Classification, but RP is not available with
fingerprints (for legal reasons). 
</p></li>
<li><p><b>Neural Networks</b>&mdash;Use this method for categorical data, where
there are fewer X variables than Y values. Useful to try if MLR gives poor
fits. Also useful if you need to fit multiple Y properties. 
</p></li>
</ul>

<p><b>By system type:</b></p>

<ul>
<li><p><b>More X variables than Y values</b>&mdash;Use PLS or KPLS. If the test
results are poor, try PCA. If they are still poor, consider partitioning Y and
using RP or Bayes.
</p></li>
<li><p><b>Many X variables</b>&mdash;Use PLS or KPLS, rather than MLR. If the
test results are poor, try PCA. If they are still poor, consider partitioning Y
and using RP or Bayes. You can also try MLR if there are more Y values than X
variables.
</p></li>
<li><p><b>Few X variables, many Y values</b>&mdash;Use MLR. If poor test
results are obtained, consider partitioning Y and using Neural Networks. 
</p></li>
<li><p><b>Multiple categorical Y properties</b>&mdash;Use Neural Networks,
provided there are more Y values than X properties.
</p></li>
</ul>

<hr />
<table width="100%">
<tr><td><p class="small"><a href="../support/legal_notice.html" target="LegalNoticeWindow">Legal Notice</a></p></td>
<td>
<table align="right">
<tr><td><p class="small">
File: applications/choosing_model.html<br />
Last updated: 04 Nov 2014
</p></td></tr>
</table>
</td></tr>
</table>
</body>
</html>